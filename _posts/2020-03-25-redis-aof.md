---
layout: post
title:  "[redis 源码走读] aof 持久化"
categories: redis
tags: redis aof
author: wenfh2020
---

aof (Append Only File) 是 redis 持久化的其中一种方式。

服务器接收的每个写入操作命令，都会追加记录到 aof 文件末尾，当服务器重新启动时，记录的命令会重新载入到服务器内存还原数据。这一章我们走读一下源码，看看 aof 持久化的数据结构和应用场景是怎样的。

> 主要源码逻辑在 `aof.c` 文件中。

* content
{:toc}

---

在了解 redis 持久化功能前，可以先看看 redis 作者这两篇文章：

* [Redis Persistence](https://redis.io/topics/persistence#how-durable-is-the-append-only-file)
* [Redis persistence demystified](http://oldblog.antirez.com/post/redis-persistence-demystified.html)

> 链接可能被墙，可以用国内搜索引擎搜索下对应的文章题目。

---

## 开启 aof 持久化模式

可以看一下 [redis.conf](https://github.com/antirez/redis/blob/unstable/redis.conf) 有关 aof 持久化配置，有redis 作者丰富的注释内容。

```shell
# 持久化方式 (yes - aof) / (no - rdb)
appendonly yes

# aof 文件名，默认 "appendonly.aof"
appendfilename "appendonly.aof"
```

---

## 结构

### aof 文件命令结构

![aof 文件结构](/images/2020-03-28-15-38-27.png)

**aof 文件可以由 redis 协议命令组成文本文件**。 第一次启动 redis，执行第一个写命令： `set key1111 1111`。我们观察一下 aof 文件：

* redis 记录了 `select` 数据库命令，`^M` 是 `cat` 命令打印的 `\r\n`。

```shell
# cat -v appendonly.aof
*2^M
$6^M
SELECT^M
$1^M
0^M
*3^M
$3^M
set^M
$7^M
key1111^M
$4^M
1111^M
```

* 命令存储文本。

```shell
# set key1111 1111
*3\r\n$3\r\nset\r\n$7\r\nkey1111$4\r\n$1111\r\n
```

* RESP 协议格式，以 `\r\n` 作为分隔符，目的是：可以用 `fgets`，将文件数据一行一行读出来。

```shell
*<命令参数个数>\r\n$<第1个参数字符串长度>\r\n$<第1个参数字符串>\r\n$<第2个参数字符串长度>\r\n$<第2个参数字符串>\r\n$<第n个参数字符串长度>\r\n$<第n个参数字符串>
```

* aof 追加命令记录源码。

```c
sds catAppendOnlyGenericCommand(sds dst, int argc, robj **argv) {
    char buf[32];
    int len, j;
    robj *o;

    // 命令参数个数
    buf[0] = '*';
    len = 1+ll2string(buf+1,sizeof(buf)-1,argc);
    buf[len++] = '\r';
    buf[len++] = '\n';
    dst = sdscatlen(dst,buf,len);

    for (j = 0; j < argc; j++) {
        o = getDecodedObject(argv[j]);
        // 参数字符串长度
        buf[0] = '$';
        len = 1+ll2string(buf+1,sizeof(buf)-1,sdslen(o->ptr));
        buf[len++] = '\r';
        buf[len++] = '\n';
        dst = sdscatlen(dst,buf,len);
        // 参数
        dst = sdscatlen(dst,o->ptr,sdslen(o->ptr));
        dst = sdscatlen(dst,"\r\n",2);
        decrRefCount(o);
    }
    return dst;
}
```

---

### aof 和 rdb 混合结构

![rdb aof 混合结构](/images/2020-03-28-16-19-34.png)

**redis 支持 aof 和 rdb 持久化同时使用**，rdb 和 aof 存储格式同时存储在一个 aof 文件中。

rdb 持久化速度快，而且落地文件小，这个优势理应加强使用。redis 持久化目前有两种方式，最终结合为一种方式，使其更加高效，这是 redis 作者一直努力的目标。

> 有关 rdb 持久化，可以参考我的帖子：
> 
> [[redis 源码走读] rdb 持久化 - 文件结构](https://wenfh2020.com/2020/03/19/redis-rdb-struct/)
> 
> [[redis 源码走读] rdb 持久化 - 应用场景](https://wenfh2020.com/2020/03/19/redis-rdb-application/)

* 可以通过配置，aof 持久化模式下，内存数据可以重写存储为 rdb 格式的 aof 文件。

```shell
# redis.conf

# 开启 aof 持久化模式
appendonly yes

# [RDB file][AOF tail] 支持 aof 和 rdb 混合持久化。
aof-use-rdb-preamble yes
```

```c
// rdb 持久化时，添加 aof 标识。
int rdbSaveInfoAuxFields(rio *rdb, int rdbflags, rdbSaveInfo *rsi) {
    ...
    if (rdbSaveAuxFieldStrInt(rdb,"aof-preamble",aof_preamble) == -1) return -1;
    ...
}
```

* redis 第一次启动后，执行第二个命令 `bgrewriteaof` 重写 aof 文件。

```shell
# cat -v appendonly.aof
REDIS0009�      redis-ver^K999.999.999�
redis-bits�@�^Ectime�M-^J�}^�^Hused-mem�^Pl^Q^@�^Laof-preamble
�^A�^@�^A^@^@^Gkey1111�W^D��^L�6Afi�
```

* redis 第一次启动后，执行第三个命令 `set key2222 2222`，aof 文件结构展示了 rdb 和 aof 结合存储方式。

```shell
# cat -v appendonly.aof
REDIS0009�      redis-ver^K999.999.999�
redis-bits�@�^Ectime�M-^J�}^�^Hused-mem�^Pl^Q^@�^Laof-preamble
�^A�^@�^A^@^@^Gkey1111�W^D��^L�6Afi�*2^M
$6^M
SELECT^M
$1^M
0^M
*3^M
$3^M
set^M
$7^M
key2222^M
$4^M
2222^M
```

---

## 持久化策略

### 策略

磁盘 I/O 速度慢，redis 作为高性能的缓存数据库，在平衡性能和持久化上，提供了几个存储策略：

> aof 持久化，每秒刷新一次缓存到磁盘，这是 redis aof 持久化默认的操作，兼顾性能和持久化。如果使用场景数据很重要，可以设置每条命令刷新磁盘一次，但是速度会非常慢。如果 redis 只作为缓存，持久化不那么重要，那么刷盘行为交给 Linux 系统管理。

* 每秒将新命令缓存刷新到磁盘。速度足够快，如果 redis 发生异常，您可能会丢失1秒的数据。

```shell
# redis.conf
appendfsync everysec
```

* 每次将新命令刷新到磁盘，非常非常慢，但是非常安全。

```shell
# redis.conf
appendfsync always
```

* redis 不主动刷新文件缓存到磁盘，只需将数据交给操作系统即可。速度更快，但是更不安全。一般情况下，Linux 使用此配置每30秒刷新一次数据。

```shell
# redis.conf
appendfsync no
```

### 流程原理

数据与设备的交互流程：

![数据持久化流程](/images/2020-03-29-15-16-07.png)

1. client 向 redis 服务发送写命令。
2. redis 服务接收到 client 发送的写命令，存储于 redis 进程内存中（redis 服务缓存）。
3. redis 服务调用接口write 将进程内存数据写入文件，fflush 将文件数据刷新到内核缓冲区。

    ```c
    void flushAppendOnlyFile(int force) {
        ...
        nwritten = aofWrite(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));
        ...
    }
    ```

4. redis 服务调用接口(`redis_fsync`)，将文件在内核缓冲区的数据刷新到磁盘缓冲区中。

    ```c
    /* Define redis_fsync to fdatasync() in Linux and fsync() for all the rest */
    #ifdef __linux__
    #define redis_fsync fdatasync
    #else
    #define redis_fsync fsync
    #endif
    ```

5. 磁盘控制器将磁盘缓冲区数据写入到磁盘物理介质中。

流程走到第 5 步，数据才算真正持久化成功。其中 2-4 步骤，一般情况下，系统会提供对外接口给服务控制，但是第 5 步没有接口，redis 服务控制不了磁盘缓存写入物理介质。一般情况下，进程正常退出或者崩溃退出，第 5 步机器系统会执行的。但是如果断电情况或其他物理异常，这样磁盘数据还是会丢失一部分。

---

如果用 `appendfsync everysec` 配置，正常情况程序退出可能会丢失 1 - 2 秒数据，但是断电等物理情况导致系统终止，丢失的数据就不可预料了。

> 参考 [Redis persistence demystified](http://oldblog.antirez.com/post/redis-persistence-demystified.html)

---

### 策略实现

```c
#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */

// 刷新缓存到磁盘。
void flushAppendOnlyFile(int force) {
    ssize_t nwritten;
    int sync_in_progress = 0;
    mstime_t latency;

    // 新的命令数据是先写入 aof 缓冲区的，所以先判断缓冲区是否有数据需要刷新到磁盘。
    if (sdslen(server.aof_buf) == 0) {
        /* 每秒刷新策略，有可能存在缓冲区是空的，但是还有数据没刷新磁盘的情况，需要执行刷新操作。
         * 当异步线程还有刷盘任务没有完成，新的刷盘任务是不会执行的，但是 aof_buf 已经写进了
         * 文件缓存，aof_buf 缓存任务已经完成需要清空。只是文件缓存还没刷新到磁盘，数据只在文件缓存
         * 里，还算不上最终落地，需要调用 redis_fsync 才会将文件缓存刷新到磁盘。* aof_fsync_offset 才会最后更新到刷盘的位置*/
        if (server.aof_fsync == AOF_FSYNC_EVERYSEC &&
            server.aof_fsync_offset != server.aof_current_size &&
            server.unixtime > server.aof_last_fsync &&
            !(sync_in_progress = aofFsyncInProgress())) {
            goto try_fsync;
        } else {
            return;
        }
    }

    // 每秒刷新策略，采用的是后台线程刷新方式，检查后台线程是否还有刷新任务没完成。
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC)
        sync_in_progress = aofFsyncInProgress();

    // 部分操作需要 force 强制写入，不接受延时。例如退出 redis 服务。
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC && !force) {
        if (sync_in_progress) {
            if (server.aof_flush_postponed_start == 0) {
                // 如果后台线程还有刷新任务，当前刷新需要延后操作。
                server.aof_flush_postponed_start = server.unixtime;
                return;
            } else if (server.unixtime - server.aof_flush_postponed_start < 2) {
                // 延时操作不能超过 2 秒，否则强制执行。
                return;
            }

            // 延时超时，强制执行。
            server.aof_delayed_fsync++;
            serverLog(LL_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.");
        }
    }

    ...

    // 写缓冲区数据到文件。
    nwritten = aofWrite(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));
    ...
    /* We performed the write so reset the postponed flush sentinel to zero. */
    server.aof_flush_postponed_start = 0;

    // 处理写文件异常
    if (nwritten != (ssize_t)sdslen(server.aof_buf)) {
        static time_t last_write_error_log = 0;
        int can_log = 0;

        // 设置异常日志打印频率
        if ((server.unixtime - last_write_error_log) > AOF_WRITE_LOG_ERROR_RATE) {
            can_log = 1;
            last_write_error_log = server.unixtime;
        }

        /* Log the AOF write error and record the error code. */
        if (nwritten == -1) {
            if (can_log) {
                serverLog(LL_WARNING,"Error writing to the AOF file: %s",
                    strerror(errno));
                server.aof_last_write_errno = errno;
            }
        } else {
            if (can_log) {
                serverLog(LL_WARNING,"Short write while writing to "
                                       "the AOF file: (nwritten=%lld, "
                                       "expected=%lld)",
                                       (long long)nwritten,
                                       (long long)sdslen(server.aof_buf));
            }

            /* 写入了部分数据，新写入的数据有可能是不完整的命令。这样会导致 redis 启动时，
             * 解析 aof 文件失败，所以需要将文件截断到上一次有效写入的位置。*/
            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {
                if (can_log) {
                    serverLog(LL_WARNING, "Could not remove short write "
                             "from the append-only file.  Redis may refuse "
                             "to load the AOF the next time it starts.  "
                             "ftruncate: %s", strerror(errno));
                }
            } else {
                /* If the ftruncate() succeeded we can set nwritten to
                 * -1 since there is no longer partial data into the AOF. */
                nwritten = -1;
            }
            server.aof_last_write_errno = ENOSPC;
        }

        // 处理错误
        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {
            // 命令实时更新策略下，如果出现写文件错误，需要关闭服务。
            serverLog(LL_WARNING,"Can't recover from AOF write error when the AOF fsync policy is 'always'. Exiting...");
            exit(1);
        } else {
            /* 其它策略，出现写入错误，更新写入成功部分，没写成功部分则在时钟里定时检查，重新写入。*/
            server.aof_last_write_status = C_ERR;

            if (nwritten > 0) {
                server.aof_current_size += nwritten;
                sdsrange(server.aof_buf,nwritten,-1);
            }
            return; /* We'll try again on the next call... */
        }
    } else {
        // 之前持久化异常，现在已经正常恢复，解除异常标识。
        if (server.aof_last_write_status == C_ERR) {
            serverLog(LL_WARNING,
                "AOF write error looks solved, Redis can write again.");
            server.aof_last_write_status = C_OK;
        }
    }
    server.aof_current_size += nwritten;

    // 持久化成功，清空 aof 缓冲区。
    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) < 4000) {
        sdsclear(server.aof_buf);
    } else {
        sdsfree(server.aof_buf);
        server.aof_buf = sdsempty();
    }

try_fsync:
    // 检查当有子进程在操作时是否允许刷新文件缓存到磁盘。
    if (server.aof_no_fsync_on_rewrite && hasActiveChildProcess())
        return;

    // 刷新文件缓存到磁盘。
    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {
        latencyStartMonitor(latency);
        redis_fsync(server.aof_fd); /* Let's try to get this data on the disk */
        latencyEndMonitor(latency);
        latencyAddSampleIfNeeded("aof-fsync-always",latency);
        server.aof_fsync_offset = server.aof_current_size;
        server.aof_last_fsync = server.unixtime;
    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &&
                server.unixtime > server.aof_last_fsync)) {
        if (!sync_in_progress) {
            // 将刷新文件缓存到磁盘操作添加到异步线程处理。
            aof_background_fsync(server.aof_fd);
            server.aof_fsync_offset = server.aof_current_size;
        }
        server.aof_last_fsync = server.unixtime;
    }
}
```

---

## 异步持久化

redis 作为高性能缓存系统，它的主逻辑都在主进程主线程中实现运行的。而持久化写磁盘是一个低效缓慢操作，因此redis 一般情况下不允许这个操作在主线程中运行。这样 redis 开启了后台线程，用来异步处理任务，保障主线程可以高速运行。

* 添加异步任务

```c
/* Define redis_fsync to fdatasync() in Linux and fsync() for all the rest */
#ifdef __linux__
#define redis_fsync fdatasync
#else
#define redis_fsync fsync
#endif

void flushAppendOnlyFile(int force) {
    ...
    else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &&
                server.unixtime > server.aof_last_fsync)) {
        // 每秒刷新缓存到磁盘一次。
        if (!sync_in_progress) {
            // 添加任务到后台线程。
            aof_background_fsync(server.aof_fd);
            server.aof_fsync_offset = server.aof_current_size;
        }
        server.aof_last_fsync = server.unixtime;
    }
    ...
}

// 添加异步任务
void aof_background_fsync(int fd) {
    bioCreateBackgroundJob(BIO_AOF_FSYNC,(void*)(long)fd,NULL,NULL);
}
```

* 异步线程刷新缓存到磁盘。

```c
// 后台异步线程创建
void bioInit(void) {
    ...
    for (j = 0; j < BIO_NUM_OPS; j++) {
        void *arg = (void*)(unsigned long) j;
        // 创建线程
        if (pthread_create(&thread,&attr,bioProcessBackgroundJobs,arg) != 0) {
            serverLog(LL_WARNING,"Fatal: Can't initialize Background Jobs.");
            exit(1);
        }
        bio_threads[j] = thread;
    }
}

// 添加异步任务
void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3) {
    struct bio_job *job = zmalloc(sizeof(*job));

    job->time = time(NULL);
    job->arg1 = arg1;
    job->arg2 = arg2;
    job->arg3 = arg3;
    pthread_mutex_lock(&bio_mutex[type]);
    listAddNodeTail(bio_jobs[type],job);
    bio_pending[type]++;
    pthread_cond_signal(&bio_newjob_cond[type]);
    pthread_mutex_unlock(&bio_mutex[type]);
}

// 线程处理
void *bioProcessBackgroundJobs(void *arg) {
    ...
    else if (type == BIO_AOF_FSYNC) {
        // 刷新内核缓存到磁盘。
        redis_fsync((long)job->arg1);
    }
    ...
}
```

---

## 应用场景

### 启动加载

redis 启动，程序会模拟一个客户端加载从 aof 文件读出的命令。

> aof 持久化支持 aof 和 rdb 混合模式，参考上面的 `aof 和 rdb 混合结构`

```c
int loadAppendOnlyFile(char *filename) {
    ...
    // 程序模拟一个客户端执行从 aof 文件读出的命令。
    fakeClient = createAOFClient();
    ...
    // 检查 aof 文件读取数据方式。
    char sig[5];
    if (fread(sig,1,5,fp) != 5 || memcmp(sig,"REDIS",5) != 0) {
        // 通过 aof 方式加载数据。
        if (fseek(fp,0,SEEK_SET) == -1) goto readerr;
    } else {
        ...
        // 通过 rdb 方式加载数据。
        if (rdbLoadRio(&rdb,RDBFLAGS_AOF_PREAMBLE,NULL) != C_OK) {
            serverLog(LL_WARNING,"Error reading the RDB preamble of the AOF file, AOF loading aborted");
            goto readerr;
        }
    }

    /* Read the actual AOF file, in REPL format, command by command. */
    while(1) {
        // 根据 aof 文件数据结构，取出数据回写内存。
        ...
    }
    ...
}
```

---

### 写命令执行流程

写命令，执行后，新的命令将会追加填充到 aof 数据缓冲区，待到合适的时候，redis 会将 aof 数据缓冲区落地，然后清空缓冲区。

* 流程

```c
call(client * c, int flags) (/Users/wenfh2020/src/other/redis/src/server.c:3266)
processCommand(client * c) (/Users/wenfh2020/src/other/redis/src/server.c:3552)
...
aeProcessEvents(aeEventLoop * eventLoop, int flags) (/Users/wenfh2020/src/other/redis/src/ae.c:457)
aeMain(aeEventLoop * eventLoop) (/Users/wenfh2020/src/other/redis/src/ae.c:515)
main(int argc, char ** argv) (/Users/wenfh2020/src/other/redis/src/server.c:5054)
```

* 执行命令，填充 aof 数据缓冲区

```c
/* Command propagation flags, see propagate() function
   + PROPAGATE_NONE (no propagation of command at all)
   + PROPAGATE_AOF (propagate into the AOF file if is enabled)
   + PROPAGATE_REPL (propagate into the replication link)
*/

#define PROPAGATE_NONE 0
#define PROPAGATE_AOF 1
#define PROPAGATE_REPL 2

void call(client *c, int flags) {
    ...
    c->cmd->proc(c);
    ...
    if (propagate_flags != PROPAGATE_NONE && !(c->cmd->flags & CMD_MODULE))
        propagate(c->cmd,c->db->id,c->argv,c->argc,propagate_flags);
    ...
}

void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc, int flags) {
    if (server.aof_state != AOF_OFF && flags & PROPAGATE_AOF)
        feedAppendOnlyFile(cmd,dbid,argv,argc);
    ...
}

// aof 缓冲区
struct redisServer {
    ...
    sds aof_buf;      /* AOF buffer, written before entering the event loop */
    ...
}

// 追加内容到 aof 文件
void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {
    sds buf = sdsempty();
    robj *tmpargv[3];

    // 命令执行，需要指定到对应数据库。
    if (dictid != server.aof_selected_db) {
        char seldb[64];

        snprintf(seldb,sizeof(seldb),"%d",dictid);
        buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n",
            (unsigned long)strlen(seldb),seldb);
        server.aof_selected_db = dictid;
    }
    ...
    // 将命令格式化为 redis 命令格式，然后追加到 aof 数据缓冲区。
    buf = catAppendOnlyGenericCommand(buf,argc,argv);
    ...
    if (server.aof_state == AOF_ON)
        server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));

    // 如果有子进程正在重写，父进程将新的数据发送给正在重写的子进程，使得重写文件数据更完备。
    if (server.aof_child_pid != -1)
        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));
    ...
}
```

* 重写过程中，父进程接收到新的命令，父进程发送给子进程，对重写数据进行追加。

  > 父子进程通过管道进行通信交互。

```c
void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {
    ...
    // 如果有子进程正在重写，父进程将新的数据发送给正在重写的子进程，使得重写文件数据更完备。
    if (server.aof_child_pid != -1)
        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));
    ...
}

// 将数据保存到重写缓冲区链表。然后通过父子进程管道进行数据传输
void aofRewriteBufferAppend(unsigned char *s, unsigned long len) {}

// 父进程通过管道把重写缓冲区数据，发送到子进程
void aofChildWriteDiffData(aeEventLoop *el, int fd, void *privdata, int mask) {}

// 子进程读取父进程发送的数据。
ssize_t aofReadDiffFromParent(void) {...}

// 创建父子进程通信管道
int aofCreatePipes(void) {...}

// 父子结束通信
void aofChildPipeReadable(aeEventLoop *el, int fd, void *privdata, int mask) {}
```

---

### 定时保存

主要对延时刷新和写磁盘出现错误回写的检查刷新。

```c
/* Using the following macro you can run code inside serverCron() with the
 * specified period, specified in milliseconds.
 * The actual resolution depends on server.hz. */
#define run_with_period(_ms_)         \
    if ((_ms_ <= 1000 / server.hz) || \
        !(cronloops % ((_ms_) / (1000 / server.hz))))

int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ...
    // 如果有延时任务，定时检查刷新。
    if (server.aof_flush_postponed_start) flushAppendOnlyFile(0);

    // 刷新缓存到磁盘出现错误（例如：磁盘满了），定时检查回写。
    // hz 频率为 10 ，这里一般每十次时钟检查一次。
    run_with_period(1000) {
        if (server.aof_last_write_status == C_ERR)
            flushAppendOnlyFile(0);
    }
    ...
    server.cronloops++;
    return 1000/server.hz;
}
```

---

### 重写

服务器接收到写入操作命令会追加到 aof 文件，那么 aof 文件相当于一个流水文件。随着时间推移，文件将会越来越大。然而 aof 文件主要目的是为了持久化，并不是为了记录服务器流水。这些流水命令有可能很多是冗余的，需要重新整理——通过**重写**来减小 aof 文件体积。

例如下面 4 条命令，会追加记录到 aof 文件，因为对同一个 key 操作，内存里最终数据 key1 对应的数据是 4，这样前面 3 条历史命令是冗余的，通过重写功能，aof 文件只留下 key 对应的最新的 value。

```shell
set key1 1
set key1 2
set key1 3
set key1 4
```

---

#### 重写方式

* 通过命令 [`BGREWRITEAOF`](https://redis.io/commands/bgrewriteaof) 重写。

```c
void bgrewriteaofCommand(client *c) {
    if (server.aof_child_pid != -1) {
        // 当重写正在进行时，返回错误。
        addReplyError(c,"Background append only file rewriting already in progress");
    } else if (hasActiveChildProcess()) {
        // 当有其它子进程正在进行工作时，延后执行。
        server.aof_rewrite_scheduled = 1;
        addReplyStatus(c,"Background append only file rewriting scheduled");
    } else if (rewriteAppendOnlyFileBackground() == C_OK) {
        // 异步执行重写
        addReplyStatus(c,"Background append only file rewriting started");
    } else {
        // 重写操作失败，检查原因。
        addReplyError(c,"Can't execute an AOF background rewriting. "
                        "Please check the server logs for more information.");
    }
}
```

* 时钟定期检查 redis 使用内存大小，当超过配置的阈值，触发自动重写。

```shell
# redis.conf

# 当前增加的内存超过上一次重写后的内存百分比，才会触发自动重写。
auto-aof-rewrite-percentage 100

# 内存重写下限
auto-aof-rewrite-min-size 64mb
```

```c
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ...
    /* Trigger an AOF rewrite if needed. */
    if (server.aof_state == AOF_ON &&
        !hasActiveChildProcess() &&
        server.aof_rewrite_perc &&
        server.aof_current_size > server.aof_rewrite_min_size)
    {
        long long base = server.aof_rewrite_base_size ?
            server.aof_rewrite_base_size : 1;
        long long growth = (server.aof_current_size*100/base) - 100;
        if (growth >= server.aof_rewrite_perc) {
            serverLog(LL_NOTICE,"Starting automatic rewriting of AOF on %lld%% growth",growth);
            rewriteAppendOnlyFileBackground();
        }
    }
    ...
}
```

#### 重写实现

1. 父进程 fork 子进程实现重写逻辑。
2. 子进程创建 aof 临时文件存储重写子进程`fork-on-write` 内存到 aof 文件。
3. 子进程重写完成 fork 内存数据内容后，追加在重写过程中父进程发送的新的内容。
4. 子进程结束父子进程管道通信。
5. 更新临时文件覆盖旧的文件。

```c
// 父进程 fork 子进程进行 aof 重写
int rewriteAppendOnlyFileBackground(void) {
    ...
    if ((childpid = redisFork()) == 0) {
        ...
        if (rewriteAppendOnlyFile(tmpfile) == C_OK) {
            sendChildCOWInfo(CHILD_INFO_TYPE_AOF, "AOF rewrite");
            exitFromChild(0);
        } else {
            exitFromChild(1);
        }
    } else {
        /* Parent */
        ...
    }
    return C_OK; /* unreached */
}

// 重写 aof 实现逻辑
int rewriteAppendOnlyFile(char *filename) {
    rio aof;
    FILE *fp;
    char tmpfile[256];
    char byte;

    // 创建 aof 临时文件。
    snprintf(tmpfile,256,"temp-rewriteaof-%d.aof", (int) getpid());
    fp = fopen(tmpfile,"w");
    if (!fp) {
        serverLog(LL_WARNING, "Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): %s", strerror(errno));
        return C_ERR;
    }

    server.aof_child_diff = sdsempty();
    rioInitWithFile(&aof,fp);

    // 逐步将文件缓存刷新到磁盘。
    if (server.aof_rewrite_incremental_fsync)
        rioSetAutoSync(&aof,REDIS_AUTOSYNC_BYTES);

    startSaving(RDBFLAGS_AOF_PREAMBLE);

    // 根据配置，重写文件内容方式，rdb 或者 aof，aof 存储方式支持 rdb 和 aof 内容兼容在同一个 aof 文件。
    if (server.aof_use_rdb_preamble) {
        int error;
        if (rdbSaveRio(&aof,&error,RDBFLAGS_AOF_PREAMBLE,NULL) == C_ERR) {
            errno = error;
            goto werr;
        }
    } else {
        if (rewriteAppendOnlyFileRio(&aof) == C_ERR) goto werr;
    }

    // 进程内存更新完毕，刷新文件到磁盘。
    if (fflush(fp) == EOF) goto werr;
    if (fsync(fileno(fp)) == -1) goto werr;

    // 子进程接收父进程发送的新数据。
    int nodata = 0;
    mstime_t start = mstime();
    while(mstime()-start < 1000 && nodata < 20) {
        if (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, 1) <= 0) {
            nodata++;
            continue;
        }
        nodata = 0; /* Start counting from zero, we stop on N *contiguous*
                       timeouts. */
        aofReadDiffFromParent();
    }

    // 子进程通知父进程不要发新的数据了。
    if (write(server.aof_pipe_write_ack_to_parent,"!",1) != 1) goto werr;
    if (anetNonBlock(NULL,server.aof_pipe_read_ack_from_parent) != ANET_OK)
        goto werr;

    // 父进程收到子进程的结束通知，发送确认给子进程。
    if (syncRead(server.aof_pipe_read_ack_from_parent,&byte,1,5000) != 1 ||
        byte != '!') goto werr;
    serverLog(LL_NOTICE,"Parent agreed to stop sending diffs. Finalizing AOF...");

    /* Read the final diff if any. */
    aofReadDiffFromParent();

    // 子进程接收父进程发送的内容缓存在缓冲区，将缓冲区内容追加到重写 aof 文件后。
    serverLog(LL_NOTICE,
        "Concatenating %.2f MB of AOF diff received from parent.",
        (double) sdslen(server.aof_child_diff) / (1024*1024));
    if (rioWrite(&aof,server.aof_child_diff,sdslen(server.aof_child_diff)) == 0)
        goto werr;

    // 内容写入文件完毕，刷新文件缓存到磁盘。
    if (fflush(fp) == EOF) goto werr;
    if (fsync(fileno(fp)) == -1) goto werr;
    if (fclose(fp) == EOF) goto werr;

    // 新的重写 aof 文件，覆盖旧的文件。
    if (rename(tmpfile,filename) == -1) {
        serverLog(LL_WARNING,"Error moving temp append only file on the final destination: %s", strerror(errno));
        unlink(tmpfile);
        stopSaving(0);
        return C_ERR;
    }
    serverLog(LL_NOTICE,"SYNC append only file rewrite performed");
    stopSaving(1);
    return C_OK;

werr:
    serverLog(LL_WARNING,"Write error writing append only file on disk: %s", strerror(errno));
    fclose(fp);
    unlink(tmpfile);
    stopSaving(0);
    return C_ERR;
}
```


---

## 调试

我一直认为：看文档和结合源码调试是理解一个项目的最好方法。

* gdb 调试，在自己感兴趣的地方设下断点，通过调试熟悉 redis aof 持久化工作流程。
  
  > 调试方法可以参考我的帖子： [用 gdb 调试 redis](https://wenfh2020.com/2020/01/05/redis-gdb/)
  
![调试走流程](/images/2020-03-25-16-40-24.png)

* 开启日志

```shell
# redis.conf

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel notice

# Specify the log file name. Also the empty string can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile "redis.log"
```

---

## 总结

* aof 文件存储 RESP 命令，新数据追加到文件末。
* aof 存储为了避免冗余，需要设置重写处理。
* aof 有三种存储策略，默认每秒存盘一次。根据自己的使用场景，选择存储策略。
* 每秒存盘策略和重写功能通过多线程异步处理，保证主线程高性能。
* 关注 redis 的博客，多看 redis.conf 配置项，里面有很多信息量。
* aof 持久化文件支持 aof 和 rdb 方式混合存储。
* aof 与 rdb 相比文件体积大，但是容灾能力强，出现问题丢失数据少。

## 参考

* [[redis 源码走读] rdb 持久化 - 文件结构](https://wenfh2020.com/2020/03/19/redis-rdb-struct/)
* [[redis 源码走读] rdb 持久化 - 应用场景](https://wenfh2020.com/2020/03/19/redis-rdb-application/)
* [Redis persistence demystified](http://oldblog.antirez.com/post/redis-persistence-demystified.html)
* [Redis Persistence](https://redis.io/topics/persistence#how-durable-is-the-append-only-file)
* [read/write/fsync与fread/fwrite/fflush的关系和区别](https://blog.csdn.net/ybxuwei/article/details/22727565)

---

* 更精彩内容，可以关注我的博客：[wenfh2020.com](https://wenfh2020.com/)
