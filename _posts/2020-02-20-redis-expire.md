---
layout: post
title:  "redis é”®è¿‡æœŸ"
categories: redis
tags: redis expire
author: wenfh2020
--- 

* [ ] è¿‡æœŸå­˜å‚¨é€»è¾‘ã€‚
* [ ] ç»ˆç«¯é€»è¾‘ã€‚
* [ ] è¿‡æœŸç­–ç•¥ã€‚
* [ ] é›†ç¾¤åŒæ­¥è¿‡æœŸç­–ç•¥ã€‚
* [ ] æ•°æ®åº“å­˜å‚¨è¿‡æœŸç­–ç•¥ã€‚
* [ ] static çš„ä½¿ç”¨èŒƒå›´ã€‚
* [ ] çº¿ç¨‹å¼‚æ­¥å¤„ç†è¿‡æœŸï¼Œçº¿ç¨‹çš„ä½¿ç”¨ä¾‹å­ã€‚
* [ ] rememberSlaveKeyWithExpire
* [ ] å½“å†…å­˜è¾¾åˆ°æœ€å¤§å†…å­˜æ—¶ï¼Œå›æ”¶è¿‡æœŸå†…å­˜ã€‚
* [ ] å®šæœŸå¿«é€Ÿå’Œæ…¢é€Ÿæ£€æŸ¥ã€‚



* content
{:toc}

---

## æµç¨‹

![å¯¹è±¡å…³ç³»](/images/2020-02-28-15-09-01.png)

redis æ•°æ®åº“ï¼Œæ•°æ®å†…å®¹å’Œè¿‡æœŸæ—¶é—´æ˜¯åˆ†å¼€ä¿å­˜çš„ã€‚`expires` ä¿å­˜äº†é”®å€¼å¯¹åº”çš„è¿‡æœŸæ—¶é—´ã€‚

```c
typedef struct redisDb {
    dict *dict;                 /* The keyspace for this DB */
    dict *expires;              /* Timeout of keys with a timeout set */
    ...
} redisDb;
```

---

## é”®å€¼è¿‡æœŸæ£€æŸ¥

redis å¯èƒ½å­˜åœ¨å¤§é‡è¿‡æœŸæ•°æ®ï¼Œä¸€æ¬¡æ€§éå†æ£€æŸ¥ä¸å¤ªç°å®ã€‚redis æœ‰ä¸°å¯Œçš„æ•°æ®ç»“æ„ï¼Œ`key-value`ï¼Œå¯èƒ½ `key` å¯¹åº”çš„ `value` æ•°æ®ç»“æ„å¯¹è±¡(`redisObj`)é‡Œå«å¤§é‡æ•°æ®ï¼Œ`key` è¿‡æœŸäº†ï¼Œ`value` ä¹Ÿä¸å»ºè®®åœ¨è¿›ç¨‹ä¸­å®æ—¶å›æ”¶ã€‚ä¸ºäº†ä¿è¯ç³»ç»Ÿé«˜æ€§èƒ½ï¼Œæ¯æ¬¡å¤„ç†ä¸€ç‚¹ç‚¹ï¼Œé€æ¸å®Œæˆå¤§ä»»åŠ¡ï¼Œâ€œåˆ†è€Œæ²»ä¹‹â€è¿™æ˜¯ redis å¤„ç†å¤§ä»»åŠ¡çš„ä¸€è´¯ä½œé£ã€‚

* è¿‡æœŸæ•°æ®æ£€æŸ¥æœ‰ä¸‰ä¸ªç­–ç•¥ï¼š

1. è®¿é—®é”®å€¼è§¦å‘æ£€æŸ¥ã€‚
   > ä¸å¯èƒ½æ¯ä¸ªé”®éƒ½èƒ½åœ¨è¿‡æœŸåèƒ½å®æ—¶è¢«è®¿é—®è§¦å‘åˆ é™¤ï¼Œé‚£ä¹ˆéœ€è¦æ—¶é’Ÿå®šæœŸæ£€æŸ¥ã€‚
2. äº‹ä»¶é©±åŠ¨å¤„ç†äº‹ä»¶å‰è§¦å‘å¿«é€Ÿæ£€æŸ¥ã€‚
   > å°†è¿‡æœŸæ£€æŸ¥è´Ÿè½½ä¸€ç‚¹ç‚¹åˆ†æ‘Šåˆ°æ¯ä¸ªäº‹ä»¶å¤„ç†ä¸­ã€‚
3. æ—¶é’Ÿå®šæœŸæ…¢é€Ÿæ£€æŸ¥ã€‚

---

* æ•°æ®å›æ”¶æœ‰ä¸¤ä¸ªç­–ç•¥ï¼š

1. å°æ•°æ®å®æ—¶å›æ”¶ã€‚
2. å¤§æ•°æ®æ”¾åˆ°ä»»åŠ¡é˜Ÿåˆ—ï¼Œåå°çº¿ç¨‹å¤„ç†ä»»åŠ¡é˜Ÿåˆ—å›æ”¶å†…å­˜ã€‚

---

### è®¿é—®æ£€æŸ¥

```c
/* Set an expire to the specified key. If the expire is set in the context
 * of an user calling a command 'c' is the client, otherwise 'c' is set
 * to NULL. The 'when' parameter is the absolute unix time in milliseconds
 * after which the key will no longer be considered valid. */
void setExpire(client *c, redisDb *db, robj *key, long long when) {
    dictEntry *kde, *de;

    /* Reuse the sds from the main dict in the expire dict */
    kde = dictFind(db->dict,key->ptr);
    serverAssertWithInfo(NULL,key,kde != NULL);
    de = dictAddOrFind(db->expires,dictGetKey(kde));
    dictSetSignedIntegerVal(de,when);

    int writable_slave = server.masterhost && server.repl_slave_ro == 0;
    if (c && writable_slave && !(c->flags & CLIENT_MASTER))
        rememberSlaveKeyWithExpire(db,key);
}
```

---

### äº‹ä»¶è§¦å‘

åœ¨äº‹ä»¶æ¨¡å‹ï¼Œå¤„ç†æ–‡ä»¶æè¿°ç¬¦å“åº”äº‹ä»¶å‰ï¼Œè§¦å‘å¿«é€Ÿæ£€æŸ¥ã€‚

```c
int main(int argc, char **argv) {
    ...
    aeSetBeforeSleepProc(server.el,beforeSleep);
    ...
    aeMain(server.el);
    ...
}

void aeMain(aeEventLoop *eventLoop) {
    eventLoop->stop = 0;
    while (!eventLoop->stop) {
        if (eventLoop->beforesleep != NULL)
            eventLoop->beforesleep(eventLoop);
        aeProcessEvents(eventLoop, AE_ALL_EVENTS|AE_CALL_AFTER_SLEEP);
    }
}


/* This function gets called every time Redis is entering the
 * main loop of the event driven library, that is, before to sleep
 * for ready file descriptors. */
void beforeSleep(struct aeEventLoop *eventLoop) {
    ...
    /* Run a fast expire cycle (the called function will return
     * ASAP if a fast cycle is not needed). */
    if (server.active_expire_enabled && server.masterhost == NULL)
        activeExpireCycle(ACTIVE_EXPIRE_CYCLE_FAST);
    ...
}
```

---

### å®šæœŸæ£€æŸ¥

å®šæœŸæ£€æŸ¥è¿‡æœŸæ•°æ®åœ¨é€šè¿‡æ—¶é’Ÿå®ç°ã€‚

```c
// server.c
void initServer(void) {
    ...
    if (aeCreateTimeEvent(server.el, 1, serverCron, NULL, NULL) == AE_ERR) {
        serverPanic("Can't create event loop timers.");
        exit(1);
    }
    ...
}

int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    ...
    databasesCron();
    ...
}

// server.c
void databasesCron(void) {
    /* Expire keys by random sampling. Not required for slaves
     * as master will synthesize DELs for us. */
    if (server.active_expire_enabled) {
        if (server.masterhost == NULL) {
            activeExpireCycle(ACTIVE_EXPIRE_CYCLE_SLOW);
        } else {
            expireSlaveKeys();
        }
    }

    ...
}
```

redis ä¸»é€»è¾‘åœ¨å•è¿›ç¨‹ä¸­å®ç°ï¼Œè¦ä¿è¯ä¸èƒ½å½±å“ä¸»ä¸šåŠ¡é€»è¾‘å‰æä¸‹ï¼Œå¯¹è¿‡æœŸæ•°æ®çš„æ£€æŸ¥ï¼Œä¸»è¦ä¸ä¼šå¤ªå½±å“ç³»ç»Ÿæ€§èƒ½ã€‚æ£€æŸ¥è¿‡æœŸæ•°æ®ä¸»è¦ä¸‰æ–¹é¢è¿›è¡Œé™åˆ¶ï¼š

1. æ£€æŸ¥æ—¶é—´é™åˆ¶ã€‚
2. è¿‡æœŸæ•°æ®æ£€æŸ¥æ•°é‡é™åˆ¶ã€‚
3. æ£€æŸ¥è¿‡ç¨‹ä¸­è¿‡æœŸæ•°æ®æ˜¯å¦è¾¾åˆ°å¯æ¥å—æ¯”ä¾‹ã€‚

æ£€æŸ¥åˆ°æ•°æ®è¿‡æœŸï¼Œä¼šå°†è¿‡æœŸé”®å€¼ä»å­—å…¸ä¸­é€»è¾‘åˆ é™¤ï¼Œåˆ‡æ–­æ•°æ®ä¸ä¸»é€»è¾‘è”ç³»ã€‚é”®å€¼å¯¹åº”çš„æ•°æ®ï¼Œä¼šæ”¾åˆ°å¼‚æ­¥çº¿ç¨‹ä¸­åå°å›æ”¶ï¼ˆå¦‚æœé…ç½®è®¾ç½®äº†å¼‚æ­¥å›æ”¶ï¼‰ã€‚

```c
/* Try to expire a few timed out keys. The algorithm used is adaptive and
 * will use few CPU cycles if there are few expiring keys, otherwise
 * it will get more aggressive to avoid that too much memory is used by
 * keys that can be removed from the keyspace.
 *
 * Every expire cycle tests multiple databases: the next call will start
 * again from the next db, with the exception of exists for time limit: in that
 * case we restart again from the last database we were processing. Anyway
 * no more than CRON_DBS_PER_CALL databases are tested at every iteration.
 *
 * The function can perform more or less work, depending on the "type"
 * argument. It can execute a "fast cycle" or a "slow cycle". The slow
 * cycle is the main way we collect expired cycles: this happens with
 * the "server.hz" frequency (usually 10 hertz).
 *
 * However the slow cycle can exit for timeout, since it used too much time.
 * For this reason the function is also invoked to perform a fast cycle
 * at every event loop cycle, in the beforeSleep() function. The fast cycle
 * will try to perform less work, but will do it much more often.
 *
 * The following are the details of the two expire cycles and their stop
 * conditions:
 *
 * If type is ACTIVE_EXPIRE_CYCLE_FAST the function will try to run a
 * "fast" expire cycle that takes no longer than EXPIRE_FAST_CYCLE_DURATION
 * microseconds, and is not repeated again before the same amount of time.
 * The cycle will also refuse to run at all if the latest slow cycle did not
 * terminate because of a time limit condition.
 *
 * If type is ACTIVE_EXPIRE_CYCLE_SLOW, that normal expire cycle is
 * executed, where the time limit is a percentage of the REDIS_HZ period
 * as specified by the ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC define. In the
 * fast cycle, the check of every database is interrupted once the number
 * of already expired keys in the database is estimated to be lower than
 * a given percentage, in order to avoid doing too much work to gain too
 * little memory.
 *
 * The configured expire "effort" will modify the baseline parameters in
 * order to do more work in both the fast and slow expire cycles.
 */

#define CRON_DBS_PER_CALL 16 /* æ¯æ¬¡æ£€æŸ¥çš„æ•°æ®åº“ä¸ªæ•° */

#define ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP 20 /* Keys for each DB loop. */
#define ACTIVE_EXPIRE_CYCLE_FAST_DURATION 1000 /* Microseconds. */
#define ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 25 /* Max % of CPU to use. */
#define ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE 10 /* % of stale keys after which
                                                   we do extra efforts. */

void activeExpireCycle(int type) {
    /* Adjust the running parameters according to the configured expire
     * effort. The default effort is 1, and the maximum configurable effort
     * is 10. */
    unsigned long
    // åŠªåŠ›åŠ›åº¦ï¼Œé»˜è®¤ 1ï¼Œä¹Ÿå°±æ˜¯éå†è¿‡æœŸå­—å…¸çš„åŠ›åº¦ï¼ŒåŠ›åº¦è¶Šå¤§ï¼Œéå†æ•°é‡è¶Šå¤šï¼Œä½†æ˜¯æ€§èƒ½æŸè€—æ›´å¤šã€‚
    effort = server.active_expire_effort-1, /* Rescale from 0 to 9. */
    // æ¯æ¬¡å¾ªç¯éå†é”®å€¼ä¸ªæ•°ã€‚åŠ›åº¦è¶Šå¤§ï¼Œéå†ä¸ªæ•°è¶Šå¤šã€‚
    config_keys_per_loop = ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP +
                           ACTIVE_EXPIRE_CYCLE_KEYS_PER_LOOP/4*effort,
    // å¿«é€Ÿéå†æ—¶é—´èŒƒå›´ï¼ŒåŠ›åº¦è¶Šå¤§ï¼Œç»™äºˆéå†æ—¶é—´è¶Šå¤šã€‚
    config_cycle_fast_duration = ACTIVE_EXPIRE_CYCLE_FAST_DURATION +
                                 ACTIVE_EXPIRE_CYCLE_FAST_DURATION/4*effort,
    config_cycle_slow_time_perc = ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC +
                                  2*effort,
    // è¿‡æœŸé”®å¤„ç† / é‡‡æ ·ä¸ªæ•° æ¯”ä¾‹ã€‚è¾¾åˆ°å¯ä»¥æ¥å—çš„æ¯”ä¾‹ã€‚
    config_cycle_acceptable_stale = ACTIVE_EXPIRE_CYCLE_ACCEPTABLE_STALE-
                                    effort;

    /* This function has some global state in order to continue the work
     * incrementally across calls. */

    // å½“å‰è¦æ£€æŸ¥æ•°æ®çš„æ•°æ®åº“ã€‚
    static unsigned int current_db = 0; /* Last DB tested. */
    // æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ç»è¶…æ—¶ã€‚
    static int timelimit_exit = 0;      /* Time limit hit in previous call? */
    // ä¸Šä¸€æ¬¡å¿«é€Ÿæ£€æŸ¥æ•°æ®èŠ±è´¹çš„æ—¶é—´ã€‚
    static long long last_fast_cycle = 0; /* When last fast cycle ran. */

    int j, iteration = 0;
    // æ¯æ¬¡å‘¨æœŸæ£€æŸ¥çš„æ•°æ®åº“ä¸ªæ•°ã€‚redis é»˜è®¤æœ‰ 16 ä¸ªåº“ã€‚
    int dbs_per_call = CRON_DBS_PER_CALL;
    long long start = ustime(), timelimit, elapsed;

    /* When clients are paused the dataset should be static not just from the
     * POV of clients not being able to write, but also from the POV of
     * expires and evictions of keys not being performed. */
    // å¦‚æœé“¾æ¥å·²ç»åœæ­¢äº†ï¼Œé‚£ä¹ˆè¦ä¿ç•™ç°åœºï¼Œä¸è¿è¡Œé“¾æ¥ä¿®æ”¹æ•°æ®ï¼Œä¹Ÿä¸å…è®¸åˆ°æœŸæ·˜æ±°æ•°æ®ã€‚
    // ä½¿ç”¨å‘½ä»¤ â€˜pauseâ€™ æš‚åœ redis å·¥ä½œæˆ–è€…ä¸»æœåŠ¡æ­£åœ¨è¿›è¡Œä»æœåŠ¡çš„æ•…éšœè½¬ç§»ã€‚
    if (clientsArePaused()) return;

    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {
        /* Don't start a fast cycle if the previous cycle did not exit
         * for time limit, unless the percentage of estimated stale keys is
         * too high. Also never repeat a fast cycle for the same period
         * as the fast cycle total duration itself. */
        // å¿«é€Ÿæ£€æŸ¥æ•°æ®è¿˜æ²¡è¶…æ—¶ï¼Œä½†æ˜¯è¶…æ—¶æ•°æ®å¤„ç†ç™¾åˆ†æ¯”å·²ç»è¾¾åˆ°äº†å¯ä»¥æ¥å—çš„èŒƒå›´ï¼Œå¯ä»¥åœæ­¢æ£€æŸ¥äº†ã€‚
        if (!timelimit_exit &&
            server.stat_expired_stale_perc < config_cycle_acceptable_stale)
            return;

        // ä¸Šä¸€ä¸ªå‘¨æœŸå¤„ç†æ•°æ®è¶…æ—¶äº†ï¼Œé€€å‡ºã€‚
        if (start < last_fast_cycle + (long long)config_cycle_fast_duration*2)
            return;

        last_fast_cycle = start;
    }

    /* We usually should test CRON_DBS_PER_CALL per iteration, with
     * two exceptions:
     *
     * 1) Don't test more DBs than we have.
     * 2) If last time we hit the time limit, we want to scan all DBs
     * in this iteration, as there is work to do in some DB and we don't want
     * expired keys to use memory for too much time. */
    if (dbs_per_call > server.dbnum || timelimit_exit)
        dbs_per_call = server.dbnum;

    /* We can use at max 'config_cycle_slow_time_perc' percentage of CPU
     * time per iteration. Since this function gets called with a frequency of
     * server.hz times per second, the following is the max amount of
     * microseconds we can spend in this function. */
    // æ£€æŸ¥è¿‡æœŸæ•°æ®ï¼Œä½†æ˜¯ä¸èƒ½å¤ªæŸè€—èµ„æºï¼Œå¾—æœ‰ä¸ªé™åˆ¶ã€‚server.hz é»˜è®¤ä¸º 10
    timelimit = config_cycle_slow_time_perc*1000000/server.hz/100;
    timelimit_exit = 0;
    if (timelimit <= 0) timelimit = 1;

    // å¦‚æœæ˜¯å¿«é€Ÿæ¨¡å¼ï¼Œæ›´æ”¹æ£€æŸ¥å‘¨æœŸæ—¶é—´ã€‚
    if (type == ACTIVE_EXPIRE_CYCLE_FAST)
        timelimit = config_cycle_fast_duration; /* in microseconds. */

    // è¿‡æœŸæ•°æ®ä¸€èˆ¬æ˜¯å¼‚æ­¥æ–¹å¼ï¼Œæ£€æŸ¥åˆ°è¿‡æœŸæ•°æ®ï¼Œéƒ½æ˜¯ä»å­—å…¸ä¸­ç§»é™¤é”®å€¼ä¿¡æ¯ï¼Œé¿å…å†æ¬¡ä½¿ç”¨ï¼Œä½†æ˜¯æ•°æ®å›æ”¶æ”¾åœ¨åå°å›æ”¶ï¼Œä¸æ˜¯å®æ—¶çš„ï¼Œæœ‰æ•°æ®æœ‰å¯èƒ½è¿˜å­˜åœ¨æ•°æ®åº“é‡Œã€‚éœ€è¦è¿›è¡Œç»Ÿè®¡ä¸€ä¸‹ã€‚
    /* Accumulate some global stats as we expire keys, to have some idea
     * about the number of keys that are already logically expired, but still
     * existing inside the database. */
    // æ£€æŸ¥æ•°æ®ä¸ªæ•°ã€‚
    long total_sampled = 0;
    // æ£€æŸ¥æ•°æ®ï¼Œæ•°æ®å·²ç»è¿‡æœŸçš„ä¸ªæ•°ã€‚
    long total_expired = 0;

    for (j = 0; j < dbs_per_call && timelimit_exit == 0; j++) {
        /* Expired and checked in a single loop. */
        unsigned long expired, sampled;

        redisDb *db = server.db+(current_db % server.dbnum);

        /* Increment the DB now so we are sure if we run out of time
         * in the current DB we'll restart from the next. This allows to
         * distribute the time evenly across DBs. */
        current_db++;

        /* Continue to expire if at the end of the cycle there are still
         * a big percentage of keys to expire, compared to the number of keys
         * we scanned. The percentage, stored in config_cycle_acceptable_stale
         * is not fixed, but depends on the Redis configured "expire effort". */
        // éå†æ•°æ®åº“æ£€æŸ¥è¿‡æœŸæ•°æ®ï¼Œç›´åˆ°è¶…å‡ºæ£€æŸ¥å‘¨æœŸæ—¶é—´ï¼Œæˆ–è€…è¿‡æœŸæ•°æ®æ¯”ä¾‹å·²ç»å¾ˆå°‘äº†ã€‚
        do {
            // num æ•°æ®é‡ï¼Œslots å“ˆå¸Œè¡¨å¤§å°ï¼ˆå­—å…¸æ•°æ®å¦‚æœæ­£åœ¨è¿ç§»ï¼ŒåŒè¡¨å¤§å°ï¼‰
            unsigned long num, slots;
            long long now, ttl_sum;
            int ttl_samples;
            iteration++;

            /* If there is nothing to expire try next DB ASAP. */
            if ((num = dictSize(db->expires)) == 0) {
                db->avg_ttl = 0;
                break;
            }
            slots = dictSlots(db->expires);
            now = mstime();

            /* When there are less than 1% filled slots, sampling the key
             * space is expensive, so stop here waiting for better times...
             * The dictionary will be resized asap. */
            /* è¿‡æœŸå­˜å‚¨æ•°æ®ç»“æ„æ˜¯å­—å…¸ï¼Œæ•°æ®ç»è¿‡å¤„ç†åï¼Œå­—å…¸å­˜å‚¨çš„æ•°æ®å¯èƒ½å·²ç»å¾ˆå°‘ï¼Œ
             * ä½†æ˜¯å­—å…¸è¿˜æ˜¯å¤§å­—å…¸ï¼Œè¿™æ ·éå†æ•°æ®æœ‰æ•ˆå‘½ä¸­ç‡ä¼šå¾ˆä½ï¼Œå¤„ç†èµ·æ¥ä¼šæµªè´¹èµ„æºï¼Œ
             * è¿™ç§æƒ…å†µä¸è¿›è¡Œå¤„ç†äº†ã€‚åé¢çš„è®¿é—®ä¼šå¾ˆå¿«è§¦å‘å­—å…¸çš„ç¼©å®¹ï¼Œç¼©å®¹åå†è¿›è¡Œå¤„ç†æ•ˆç‡æ›´é«˜ã€‚*/
            if (num && slots > DICT_HT_INITIAL_SIZE &&
                (num*100/slots < 1)) break;

            /* The main collection cycle. Sample random keys among keys
             * with an expire set, checking for expired ones. */
            // è¿‡æœŸçš„æ•°æ®ä¸ªæ•°ã€‚
            expired = 0;
            // æ£€æŸ¥çš„æ•°æ®ä¸ªæ•°ã€‚
            sampled = 0;
            // æ²¡æœ‰è¿‡æœŸçš„æ•°æ®æ—¶é—´å·®ä¹‹å’Œã€‚
            ttl_sum = 0;
            // æ²¡æœ‰è¿‡æœŸçš„æ•°æ®ä¸ªæ•°ã€‚
            ttl_samples = 0;

            // æ¯æ¬¡æ£€æŸ¥çš„æ•°æ®é™åˆ¶ã€‚
            if (num > config_keys_per_loop)
                num = config_keys_per_loop;

            /* Here we access the low level representation of the hash table
             * for speed concerns: this makes this code coupled with dict.c,
             * but it hardly changed in ten years.
             *
             * Note that certain places of the hash table may be empty,
             * so we want also a stop condition about the number of
             * buckets that we scanned. However scanning for free buckets
             * is very fast: we are in the cache line scanning a sequential
             * array of NULL pointers, so we can scan a lot more buckets
             * than keys in the same time. */
            /* å“ˆå¸Œè¡¨æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„ä¸Šä¿å­˜äº†é”®å€¼ç¢°æ’çš„æ•°æ®ï¼Œç”¨é“¾è¡¨å°†ç¢°æ’æ•°æ®ä¸²è”èµ·æ¥ï¼Œ
             * æ”¾åœ¨ä¸€ä¸ªæ•°ç»„ä¸‹æ ‡ä¸‹ï¼Œä¹Ÿå°±æ˜¯æ”¾åœ¨å“ˆå¸Œè¡¨çš„ä¸€ä¸ªæ¡¶é‡Œã€‚max_buckets æ˜¯æœ€å¤§èƒ½æ£€æŸ¥çš„æ¡¶ä¸ªæ•°ã€‚
             * è·³è¿‡ç©ºæ¡¶ï¼Œä¸å¤„ç†ã€‚*/
            long max_buckets = num*20;
            // å½“å‰å·²ç»æ£€æŸ¥å“ˆå¸Œè¡¨æ¡¶çš„ä¸ªæ•°ã€‚
            long checked_buckets = 0;

            // ä¸€ä¸ªæ¡¶ä¸Šæœ‰å¯èƒ½æœ‰å¤šä¸ªæ•°æ®ã€‚æ‰€ä»¥æ£€æŸ¥ä»ä¸¤æ–¹é¢é™åˆ¶ï¼šä¸€ä¸ªæ˜¯æ•°æ®é‡ï¼Œä¸€ä¸ªæ˜¯æ¡¶çš„æ•°é‡ã€‚
            while (sampled < num && checked_buckets < max_buckets) {
                for (int table = 0; table < 2; table++) {
                    // å¦‚æœ dict æ²¡æœ‰æ­£åœ¨è¿›è¡Œæ‰©å®¹ï¼Œä¸éœ€è¦æ£€æŸ¥å®ƒçš„ç¬¬äºŒå¼ è¡¨äº†ã€‚
                    if (table == 1 && !dictIsRehashing(db->expires)) break;

                    unsigned long idx = db->expires_cursor;
                    idx &= db->expires->ht[table].sizemask;
                    dictEntry *de = db->expires->ht[table].table[idx];
                    long long ttl;

                    /* Scan the current bucket of the current table. */
                    checked_buckets++;
                    while(de) {
                        /* Get the next entry now since this entry may get
                         * deleted. */
                        dictEntry *e = de;
                        de = de->next;

                        // æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ç»è¶…æ—¶ã€‚
                        ttl = dictGetSignedIntegerVal(e)-now;

                        // å¦‚æœæ•°æ®è¿‡æœŸäº†ï¼Œè¿›è¡Œå›æ”¶å¤„ç†ã€‚
                        if (activeExpireCycleTryExpire(db,e,now)) expired++;
                        if (ttl > 0) {
                            /* We want the average TTL of keys yet
                             * not expired. */
                            ttl_sum += ttl;
                            ttl_samples++;
                        }
                        sampled++;
                    }
                }
                db->expires_cursor++;
            }
            total_expired += expired;
            total_sampled += sampled;

            /* Update the average TTL stats for this database. */
            if (ttl_samples) {
                long long avg_ttl = ttl_sum/ttl_samples;

                /* Do a simple running average with a few samples.
                 * We just use the current estimate with a weight of 2%
                 * and the previous estimate with a weight of 98%. */
                if (db->avg_ttl == 0) db->avg_ttl = avg_ttl;
                // å¯¹æ²¡è¿‡æœŸçš„æ•°æ®ï¼Œå¹³å‡è¿‡æœŸæ—¶é—´è¿›è¡Œé‡‡æ ·ï¼Œä¸Šä¸€æ¬¡ç»Ÿè®¡çš„å¹³å‡æ—¶é—´å  98 %ï¼Œæœ¬æ¬¡å  2%ã€‚
                db->avg_ttl = (db->avg_ttl/50)*49 + (avg_ttl/50);
            }

            /* We can't block forever here even if there are many keys to
             * expire. So after a given amount of milliseconds return to the
             * caller waiting for the other active expire cycle. */
            // é¿å…æ£€æŸ¥å‘¨æœŸå¤ªé•¿ï¼Œå½“å‰æ•°æ®åº“æ¯ 15 æ¬¡å¾ªç¯è¿­ä»£æ£€æŸ¥ï¼Œæ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼Œè¶…æ—¶é€€å‡ºã€‚
            if ((iteration & 0xf) == 0) { /* check once every 16 iterations. */
                elapsed = ustime()-start;
                if (elapsed > timelimit) {
                    timelimit_exit = 1;
                    server.stat_expired_time_cap_reached_count++;
                    break;
                }
            }
            /* We don't repeat the cycle for the current database if there are
             * an acceptable amount of stale keys (logically expired but yet
             * not reclaimed). */
            /* å¦‚æœæ²¡æœ‰æ£€æŸ¥åˆ°æ•°æ®ï¼Œæˆ–è€…æ£€æŸ¥æ•°æ®ï¼Œè¿‡æœŸæ•°æ®è¾¾åˆ°å¯æ¥å—æ¯”ä¾‹
             * å°±åœæ­¢å½“å‰æ•°æ®åº“åˆ°æ£€æŸ¥ï¼Œè¿›å…¥åˆ°ä¸‹ä¸€ä¸ªæ•°æ®åº“æ£€æŸ¥ã€‚*/
        } while (sampled == 0 ||
                 (expired*100/sampled) > config_cycle_acceptable_stale);
    }

    elapsed = ustime()-start;
    server.stat_expire_cycle_time_used += elapsed;
    latencyAddSampleIfNeeded("expire-cycle",elapsed/1000);

    /* Update our estimate of keys existing but yet to be expired.
     * Running average with this sample accounting for 5%. */
    double current_perc;
    if (total_sampled) {
        current_perc = (double)total_expired/total_sampled;
    } else
        current_perc = 0;

    // ä¿å­˜è¿‡æœŸæ•°æ®å æ£€æŸ¥æ•°æ®çš„æ¯”ä¾‹ã€‚
    server.stat_expired_stale_perc = (current_perc*0.05)+
                                     (server.stat_expired_stale_perc*0.95);
}
```

* å›æ”¶è¿‡æœŸæ•°æ®

```c
/* Helper function for the activeExpireCycle() function.
 * This function will try to expire the key that is stored in the hash table
 * entry 'de' of the 'expires' hash table of a Redis database.
 *
 * If the key is found to be expired, it is removed from the database and
 * 1 is returned. Otherwise no operation is performed and 0 is returned.
 *
 * When a key is expired, server.stat_expiredkeys is incremented.
 *
 * The parameter 'now' is the current time in milliseconds as is passed
 * to the function to avoid too many gettimeofday() syscalls. */
int activeExpireCycleTryExpire(redisDb *db, dictEntry *de, long long now) {
    long long t = dictGetSignedIntegerVal(de);
    if (now > t) {
        sds key = dictGetKey(de);
        robj *keyobj = createStringObject(key,sdslen(key));

        // é€šçŸ¥ä»æœåŠ¡ï¼Œæ•°æ®è¿›è¡Œä¸»ä»åŒæ­¥ï¼Œå¦‚æœå­˜å‚¨æ ¼å¼æ˜¯ aofï¼Œå¾€æœ¬åœ°å­˜å‚¨æ·»åŠ ä¸€æ¡åˆ é™¤æŒ‡ä»¤ã€‚
        propagateExpire(db,keyobj,server.lazyfree_lazy_expire);
        if (server.lazyfree_lazy_expire)
            dbAsyncDelete(db,keyobj);
        else
            dbSyncDelete(db,keyobj);
        notifyKeyspaceEvent(NOTIFY_EXPIRED,
            "expired",keyobj,db->id);
        trackingInvalidateKey(keyobj);
        decrRefCount(keyobj);
        server.stat_expiredkeys++;
        return 1;
    } else {
        return 0;
    }
}
```

* redis.conf

å¤„ç†åå°ä»»åŠ¡çš„é¢‘ç‡ï¼Œé¢‘ç‡è¶Šé«˜ï¼Œå¤„ç†åå°ä»»åŠ¡è¶Šå¤šï¼Œä½†æ˜¯æ¶ˆè€—èµ„æºä¹Ÿè¶Šé«˜ï¼Œå¯ä»¥è‡ªè¡Œè°ƒèŠ‚ï¼Œä½†æ˜¯æœ€å¥½ä¸è¦å½±å“åˆ°ä¸»é€»è¾‘çš„ä½¿ç”¨ã€‚

```shell
# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeout, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are performed with the same frequency, but Redis checks for
# tasks to perform according to the specified "hz" value.
#
# By default "hz" is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10
```

---

## æ•°æ®å›æ”¶ç­–ç•¥

è¿‡æœŸæ•°æ®å›æ”¶ç­–ç•¥ï¼š

1. åŒæ­¥å›æ”¶ã€‚
2. å¼‚æ­¥å›æ”¶ã€‚

`redis.conf` é…ç½®é‡Œé¢æœ‰æ¯”è¾ƒè¯¦ç»†çš„è¿‡æœŸé”®å¤„ç†ç­–ç•¥æè¿°ã€‚

> æ–‡æ¡£æå…¶è¯¦ç»†ï¼Œä½œè€…çš„è€å¿ƒï¼Œåœ¨å¼€æºé¡¹ç›®ä¸­ï¼Œæ˜¯æ¯”è¾ƒå°‘è§çš„ ğŸ‘ã€‚

```shell
############################# LAZY FREEING ####################################

# Redis has two primitives to delete keys. One is called DEL and is a blocking
# deletion of the object. It means that the server stops processing new commands
# in order to reclaim all the memory associated with an object in a synchronous
# way. If the key deleted is associated with a small object, the time needed
# in order to execute the DEL command is very small and comparable to most other
# O(1) or O(log_N) commands in Redis. However if the key is associated with an
# aggregated value containing millions of elements, the server can block for
# a long time (even seconds) in order to complete the operation.
#
# For the above reasons Redis also offers non blocking deletion primitives
# such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and
# FLUSHDB commands, in order to reclaim memory in background. Those commands
# are executed in constant time. Another thread will incrementally free the
# object in the background as fast as possible.
#
# DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.
# It's up to the design of the application to understand when it is a good
# idea to use one or the other. However the Redis server sometimes has to
# delete keys or flush the whole database as a side effect of other operations.
# Specifically Redis deletes objects independently of a user call in the
# following scenarios:
#
# 1) On eviction, because of the maxmemory and maxmemory policy configurations,
#    in order to make room for new data, without going over the specified
#    memory limit.
# 2) Because of expire: when a key with an associated time to live (see the
#    EXPIRE command) must be deleted from memory.
# 3) Because of a side effect of a command that stores data on a key that may
#    already exist. For example the RENAME command may delete the old key
#    content when it is replaced with another one. Similarly SUNIONSTORE
#    or SORT with STORE option may delete existing keys. The SET command
#    itself removes any old content of the specified key in order to replace
#    it with the specified string.
# 4) During replication, when a replica performs a full resynchronization with
#    its master, the content of the whole database is removed in order to
#    load the RDB file just transferred.
#
# In all the above cases the default is to delete objects in a blocking way,
# like if DEL was called. However you can configure each case specifically
# in order to instead release memory in a non-blocking way like if UNLINK
# was called, using the following configuration directives:

lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
replica-lazy-flush no
```

`expire.c` æ–‡ä»¶è®°å½•æ¥è¦å¤„ç†çš„å‡ ä¸ªå‘½ä»¤ã€‚

## å®¢æˆ·ç«¯é“¾æ¥æ•°æ®åº“

å®¢æˆ·ç«¯é“¾æ¥æœåŠ¡ç«¯æ“ä½œï¼Œé»˜è®¤æ˜¯é“¾æ¥ç¬¬ä¸€ä¸ªæ•°æ®åº“ã€‚

```c
client *createClient(connection *conn) {
    ...
    selectDb(c,0);
    ...
}
```

## è®¿é—®é”®å€¼è§¦å‘æ£€æŸ¥

### åˆ é™¤

`db.c`

```c
void delCommand(client *c) {
    delGenericCommand(c,0);
}

void unlinkCommand(client *c) {
    delGenericCommand(c,1);
}

/* This command implements DEL and LAZYDEL. */
void delGenericCommand(client *c, int lazy) {
    int numdel = 0, j;

    for (j = 1; j < c->argc; j++) {
        expireIfNeeded(c->db,c->argv[j]);
        int deleted  = lazy ? dbAsyncDelete(c->db,c->argv[j]) :
                              dbSyncDelete(c->db,c->argv[j]);
        if (deleted) {
            signalModifiedKey(c->db,c->argv[j]);
            notifyKeyspaceEvent(NOTIFY_GENERIC,
                "del",c->argv[j],c->db->id);
            server.dirty++;
            numdel++;
        }
    }
    addReplyLongLong(c,numdel);
}
```

---

### åˆ¤æ–­é”®å€¼è¿‡æœŸå¤„ç†

æƒ°æ€§å¤„ç†è¿‡æœŸé”®æ¥å£ã€‚åªæœ‰ä¸»æœåŠ¡æ‰ä¼šä¸»åŠ¨æ£€æŸ¥è¿‡æœŸé”®ï¼Œä»æœåŠ¡æä¾›è¯»æ•°æ®æœåŠ¡ï¼Œä¸ä¼šæ£€æŸ¥é”®å€¼æ˜¯å¦å·²ç»è¿‡æœŸï¼Œç›´åˆ°ä¸»æœåŠ¡è¿›è¡Œæ•°æ®åŒæ­¥ï¼Œæ‰€ä»¥ä»æœåŠ¡å¤„ç†æ•°æ®æœ‰ä¸€å®šçš„å»¶åæ€§ã€‚æ‰€ä»¥ä»æœåŠ¡çš„ `keyIsExpired` ä¸æ˜¯å®æ—¶çš„ã€‚

`db.c`

```c
/* This function is called when we are going to perform some operation
 * in a given key, but such key may be already logically expired even if
 * it still exists in the database. The main way this function is called
 * is via lookupKey*() family of functions.
 *
 * The behavior of the function depends on the replication role of the
 * instance, because slave instances do not expire keys, they wait
 * for DELs from the master for consistency matters. However even
 * slaves will try to have a coherent return value for the function,
 * so that read commands executed in the slave side will be able to
 * behave like if the key is expired even if still present (because the
 * master has yet to propagate the DEL).
 *
 * In masters as a side effect of finding a key which is expired, such
 * key will be evicted from the database. Also this may trigger the
 * propagation of a DEL/UNLINK command in AOF / replication stream.
 *
 * The return value of the function is 0 if the key is still valid,
 * otherwise the function returns 1 if the key is expired. */
int expireIfNeeded(redisDb *db, robj *key) {
    if (!keyIsExpired(db,key)) return 0;

    /* If we are running in the context of a slave, instead of
     * evicting the expired key from the database, we return ASAP:
     * the slave key expiration is controlled by the master that will
     * send us synthesized DEL operations for expired keys.
     *
     * Still we try to return the right information to the caller,
     * that is, 0 if we think the key should be still valid, 1 if
     * we think the key is expired at this time. */
    if (server.masterhost != NULL) return 1;

    /* Delete the key */
    server.stat_expiredkeys++;
    // ä¼ æ’­æ•°æ®æ›´æ–°ï¼Œä¼ æ’­åˆ°é›†ç¾¤ä¸­å»ï¼Œå¦‚æœæ•°æ®åº“æ˜¯ `aof` æ ¼å¼å­˜å‚¨ï¼Œæ›´æ–°è½åœ° `aof` æ–‡ä»¶ã€‚
    propagateExpire(db,key,server.lazyfree_lazy_expire);
    notifyKeyspaceEvent(NOTIFY_EXPIRED,
        "expired",key,db->id);
    return server.lazyfree_lazy_expire ? dbAsyncDelete(db,key) :
                                         dbSyncDelete(db,key);
}
```

### è®¾ç½®è¿‡æœŸæ—¶é—´

è¿‡æœŸå‡½æ•°ï¼Œåœ¨ä¸»æœåŠ¡ä¼šè§¦å‘é”®å€¼è¿‡æœŸåˆ é™¤ï¼Œä»æœåŠ¡æ”¶åˆ°è¿‡æœŸå‡½æ•°åªä¼šè®¾ç½®é”®å€¼å¯¹åº”è¿‡æœŸæ—¶é—´ï¼Œä¸ä¼šåˆ é™¤è¿‡æœŸé”®ã€‚ä»æœåŠ¡å™¨éœ€è¦ç­‰å¾…ä¸»æœåŠ¡ç­‰åˆ é™¤é”®æ“ä½œï¼Œè¿›è¡Œæ•°æ®åŒæ­¥åˆ é™¤ã€‚

`expire.c`

```c
/* EXPIRE key seconds */
void expireCommand(client *c) {
    expireGenericCommand(c,mstime(),UNIT_SECONDS);
}

/* EXPIREAT key time */
void expireatCommand(client *c) {
    expireGenericCommand(c,0,UNIT_SECONDS);
}

/* PEXPIRE key milliseconds */
void pexpireCommand(client *c) {
    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);
}

/* PEXPIREAT key ms_time */
void pexpireatCommand(client *c) {
    expireGenericCommand(c,0,UNIT_MILLISECONDS);
}

/*-----------------------------------------------------------------------------
 * Expires Commands
 *----------------------------------------------------------------------------*/

/* This is the generic command implementation for EXPIRE, PEXPIRE, EXPIREAT
 * and PEXPIREAT. Because the commad second argument may be relative or absolute
 * the "basetime" argument is used to signal what the base time is (either 0
 * for *AT variants of the command, or the current time for relative expires).
 *
 * unit is either UNIT_SECONDS or UNIT_MILLISECONDS, and is only used for
 * the argv[2] parameter. The basetime is always specified in milliseconds. */
void expireGenericCommand(client *c, long long basetime, int unit) {
    robj *key = c->argv[1], *param = c->argv[2];
    long long when; /* unix time in milliseconds when the key will expire. */

    if (getLongLongFromObjectOrReply(c, param, &when, NULL) != C_OK)
        return;

    if (unit == UNIT_SECONDS) when *= 1000;
    when += basetime;

    /* No key, return zero. */
    if (lookupKeyWrite(c->db,key) == NULL) {
        addReply(c,shared.czero);
        return;
    }

    /* EXPIRE with negative TTL, or EXPIREAT with a timestamp into the past
     * should never be executed as a DEL when load the AOF or in the context
     * of a slave instance.
     *
     * Instead we take the other branch of the IF statement setting an expire
     * (possibly in the past) and wait for an explicit DEL from the master. */
     // é”®å€¼è¿‡æœŸ/æœåŠ¡æ²¡æœ‰æ­£åœ¨åŠ è½½/ä¸»æœåŠ¡
    if (when <= mstime() && !server.loading && !server.masterhost) {
        robj *aux;

        int deleted = server.lazyfree_lazy_expire ? dbAsyncDelete(c->db,key) :
                                                    dbSyncDelete(c->db,key);
        serverAssertWithInfo(c,key,deleted);
        server.dirty++;

        /* Replicate/AOF this as an explicit DEL or UNLINK. */
        aux = server.lazyfree_lazy_expire ? shared.unlink : shared.del;
        rewriteClientCommandVector(c,2,aux,key);
        signalModifiedKey(c->db,key);
        notifyKeyspaceEvent(NOTIFY_GENERIC,"del",key,c->db->id);
        addReply(c, shared.cone);
        return;
    } else {
        // é”®å€¼æ²¡æœ‰è¿‡æœŸ/æœåŠ¡æ­£åœ¨åŠ è½½/ä»æœåŠ¡ æƒ…å†µä¸‹è®¾ç½®é”®å€¼è¿‡æœŸæ—¶é—´
        setExpire(c,c->db,key,when);
        addReply(c,shared.cone);
        signalModifiedKey(c->db,key);
        notifyKeyspaceEvent(NOTIFY_GENERIC,"expire",key,c->db->id);
        server.dirty++;
        return;
    }
}
```

ä»åº“å¹¶ä¸æ˜¯ä¸èƒ½ä¿®æ”¹ï¼Œåªè¦ä¸æ˜¯ readonly å°±èƒ½è¿›è¡Œå†™æ•°æ®ã€‚


## å‚è€ƒ

* [redis è¿‡æœŸç­–ç•¥åŠå†…å­˜å›æ”¶æœºåˆ¶](https://blog.csdn.net/alex_xfboy/article/details/88959647)